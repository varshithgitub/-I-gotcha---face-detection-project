import threading
import cv2
from deepface import DeepFace
import pyodbc
from io import BytesIO
import numpy as np
from PIL import Image
import time

# Initialize the video capture
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

counter = 0
face_match = False
matched_person = None
prompt_shown = False
delay_time = 20
start_time = time.time()

# Function to fetch images from the database
def get_images_from_db():
    connection = pyodbc.connect(
        'DRIVER={ODBC Driver 17 for SQL Server};SERVER=localhost;'
        'DATABASE=face_database;TRUSTED_CONNECTION=yes;'
    )
    cursor = connection.cursor()
    cursor.execute("SELECT person_name, image_data FROM FaceImages")

    images = []
    for row in cursor.fetchall():
        person_name = row[0]
        image_data = row[1]
        img = Image.open(BytesIO(image_data))
        img = img.convert("RGB")  # Ensure image is in RGB format
        img_np = np.array(img)
        images.append((person_name, img_np))
    connection.close()
    return images

# Function to add new face to the database
def add_image_to_db(name, image):
    connection = pyodbc.connect(
        'DRIVER={ODBC Driver 17 for SQL Server};SERVER=localhost;'
        'DATABASE=face_database;TRUSTED_CONNECTION=yes;'
    )
    cursor = connection.cursor()
    img_pil = Image.fromarray(image)
    img_byte_arr = BytesIO()
    img_pil.save(img_byte_arr, format='JPEG')
    img_byte_arr = img_byte_arr.getvalue()
    cursor.execute("INSERT INTO FaceImages (person_name, image_data) VALUES (?, ?)", (name, img_byte_arr))
    connection.commit()
    connection.close()

# Fetch stored images from the database
stored_images = get_images_from_db()

# Function to check for a face match
def check_face(frame):
    global face_match, matched_person
    face_match = False

    try:
        for person_name, saved_image in stored_images:
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            saved_image_rgb = cv2.cvtColor(saved_image, cv2.COLOR_BGR2RGB)

            # Compare the frames using DeepFace
            result = DeepFace.verify(frame_rgb, saved_image_rgb)
            if result['verified']:
                face_match = True
                matched_person = person_name
                print(f"Match found with {matched_person}")
                break

    except Exception as e:
        print(f"Error in face matching: {e}")
        face_match = False

# Function to prompt user to add a new face
def ask_to_add_image(frame):
    user_input = input("No match found. Add this person? (y/n): ")
    if user_input.lower() == 'y':
        person_name = input("Enter name: ")
        add_image_to_db(person_name, frame)
        print(f"{person_name} added to database.")

# Main video capture loop
while True:
    ret, frame = cap.read()

    if ret:
        if counter % 38 == 8 and not prompt_shown:
            threading.Thread(target=check_face, args=(frame.copy(),)).start()

        counter += 1

        if face_match:
            # Display MATCH and Welcome message
            cv2.putText(frame, "MATCH!", (20, 400), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)
            cv2.putText(frame, f"Welcome {matched_person}!", (20, 450), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)
            print(f"Welcome {matched_person}!")

        else:
            # Display NO MATCH message
            cv2.putText(frame, "NO MATCH!", (20, 450), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3)
            if time.time() - start_time > delay_time and not prompt_shown:
                prompt_shown = True
                ask_to_add_image(frame.copy())
                prompt_shown = False
                start_time = time.time()

        cv2.imshow("video", frame)

        # Exit if 'q' is pressed
        if cv2.waitKey(1) == ord("q"):
            break  # Exit the loop on 'q' key

cap.release()
cv2.destroyAllWindows()
